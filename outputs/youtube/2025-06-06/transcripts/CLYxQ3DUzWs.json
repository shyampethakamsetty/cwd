{
  "channel_id": "UCqQs28K2zj2dOsc5NfXUKEg",
  "channel_name": "Benzinga",
  "video_id": "CLYxQ3DUzWs",
  "published": "2025-06-05T22:10:47+00:00",
  "title": "ðŸ”´ WATCH LIVE: Broadcom Q2 2025 Earnings Call | $AVGO",
  "transcript": "[Music] [Music] Come [Music] on. Come on. [Music] [Music] [Music] [Music] [Music] Come on. Come on. [Music] [Music] Come on. Come on. [Music] two. Welcome to Broadcoms, Inc.'s second quarter fiscal year 2025 financial results conference call. At this time for opening remarks and introductions, I would like to turn the call over to Gu, head of investor relations of Broadcom, Inc. Thank you, operator, and good afternoon, everyone. Joining me on today's call are Hawktan, president and CEO, Kirstston Spears, Chief Financial Officer, and Charlie Kawas, President Semiconductor Solutions Group. Broadcom distributed a press release and financial tables after the market closed describing our financial performance for the second quarter of fiscal year 2025. If you did not receive a copy, you may obtain the information from the investor section of the Broadcom's website at broadcom.com. This conference call is being webcast live and an audio replay of the call can be accessed for one year through the investor section of Broadcom's website. During the prepared comments, Hawk and Kirsten will be providing details of our second quarter fiscal year 2025 results, guidance for our third quarter of fiscal year 2025, as well as commentary regarding the business environment. We'll take questions after the end of our prepared comments. Please refer to our press release today and our recent filings with the SEC for information on the specific risk factors that could cause our actual results to differ materially from the forward-looking statements made on this call. In addition to US GAAP reporting, Broadcom reports certain financial measures on a non-GAAP basis. A reconciliation between GAP and non-GAAP measures is included in the table attached to today's press release. Comments made during today's call will primarily refer to our non-GAAP financial results. I will now turn the call over to Hawks. Thank you. Thank you, G. And thank you everyone for joining us today. In our fiscal Q2 2025, total revenue was a record 15 billion, up 20% yearonear. This 20% yearon-year growth was all organic as Q2 last year was the first full quarter with VMware. Now revenue was driven by continued strength in AI semiconductors and the momentum we have achieved in VMware now reflecting excellent all operating leverage Q2 consolidated adjusted IBIDA was $10 billion up 35% yearonear now let me provide more color Q2 semiconductor revenue was 8.4 billion with growth accelerating to 17% year on year up from 11% in Q1. And of course driving this growth was AI semi semiconductor revenue of over 4.4 4 billion which is up 46% yearonear and continues the trajectory of nine consecutive quarters of strong growth within this custom AI accelerators grew double digits year one year while AI networking grew over 170% year on AI networking which is based on Ethernet was robust and represented 40% of our AI revenue as a standardsbased open protocol. Ethernet enables one single fabric for both scale out and scale up and remains the preferred choice by our hypers scale customers. Our networking portfolio of tomahawk switches, Jericho routers and nicks is what's driving our success within AI clusters in hyperscalers. And the momentum continues with our breakthrough Tomahawk 6 switch just announced this week. This represents the the next generation 102.4 terabits per second switch capacity. Tom 6 enables clusters of more than 100,000 AI accelerators to be deployed in just two tiers instead of three. This flattening of the AI cluster is huge because it enables much better performance in training next generation frontier models through a lower latency, higher bandwidth and lower power. Turning to XPUs or custom accelerators, we continue to make excellent progress on the multi-year journey of enabling our three customers and four prospects to deploy custom AI accelerators. As we had articulated over six months ago, we eventually expect at least three customers to each deploy 1 million AI accelerated clusters in 2027 largely for training their frontier models. And we forecast and continue to do so a significant percentage of these deployments to be custom XPUs. These partners are still unwavering in their plan to invest despite these certain economic environment. In fact, what we seen recently is that they are doubling down on inference in order to monetize their platforms. And reflecting this, we may actually see an acceleration of XPU demand into the back half of 2026 to meet urgent demand for inference on top of the demand we have indicated for from training. And accordingly, we do anticipate now our fiscal 2025 growth rate of AI semiconductor revenue to sustain into fiscal 2026. Turning to Q our Q3 outlook as we continue our current trajectory of growth we forecast AI semiconductor revenue to be $5.1 billion up 60% yearonear which would be the 10th consecutive quarter of growth. Now turning to nonAI semiconductors in Q2. Revenue of $4 billion was down 5% yearonear. NonAI semiconductor revenue is close to the bottom has been relatively slow to recover but there are bright spots. In Q2, broadband, enterprise networking and server storage revenue were up sequentially. However, industrial was down and as as and as expected, wireless was also down due to seasonality. In Q3, we expect enterprise networking and broadband to continue to grow sequentially, but server storage, wireless and industrial are expected to be largely flat. And overall, we forecast nonAI semiconductor revenue to stay around $4 billion. Now, let me talk about our infrastructure software segment. Q2 infrastructure software revenue of 6.6 billion was up 25% yearonear above our outlook of $6.5 billion. As we have said before, this growth reflects our success in converting our enterprise customers from perpetual vSphere to the full VCF software stack subscription. Customers are increasingly turning to VCF to create a modernized private cloud on prem which will enable them to repatriate workloads from public clouds while being able to run modern containerbased applications and AI applications. Of our 10,000 largest customers, over 87% have now adopted VCF. The momentum from strong VCF sales over the past 18 months since the acquisition of VMware has created annual recurring revenue or otherwise known as ASR growth of double digits in our core infrastructure software. In Q3, we expect infrastructure software revenue to be approximately $6.7 billion, up 16% yearonear. So in total, we're guiding Q3 consolidated revenue to be approximately 15.8 billion, up 21% yearonear. We expect Q3 adjusted Ebida to be at least 66%. With that, let me turn the call over to K. Thank you, Hawk. Let me now provide additional detail on our Q2 financial performance. Consolidated revenue was a record 15 billion for the quarter, up 20% from a year ago. Gross margin was 79.4% of revenue in the quarter, better than we originally guided on product mix. Consolidated operating expenses were 2.1 billion, of which 1.5 billion was related to R&D. Q2 operating income of 9.8 billion was up 37% from a year ago with operating margin at 65% of revenue. adjusted EBIT DAW was 10 billion or 67% of revenue above our guidance of 66%. This figure excludes 142 million of depreciation. Now a review of the P&L for our two segments starting with semiconductors. Revenue for our semiconductor solution segment was 8.4 4 billion with growth accelerating to 17% year-onear driven by AI. Semiconductor revenue represented 56% of total revenue in the quarter. Gross margin for our semiconductor solution segment was approximately 69% up 140 basis points year-on-year driven by product mix. Operating expenses increased 12% year-on-year to 971 million on increased investment in R&D for leading edge AI semiconductors. Semiconductor operating margin of 57% was up 200 basis points year onear. Now moving on to infrastructure software. Revenue for infrastructure software of 6.6 6 billion was up 25% year-on-year and represented 44% of total revenue. Gross margin for infrastructure software was 93% in the quarter compared to 88% a year ago. Operating expenses were 1.1 billion in the quarter resulting in infrastructure software operating margin of approximately 76%. This compares to operating margin of 60% a year ago. This year-on-year improvement reflects our disciplined integration of VMware. Moving on to cash flow. Free cash flow in the quarter was 6.4 billion and represented 43% of revenue. Free cash flow as a percentage of revenue continues to be impacted by increased interest expense from debt related to the VMware acquisition and increased cash taxes. We spent 144 million on capital expenditures. Day sales outstanding were 34 days in the second quarter compared to 40 days a year ago. We ended the second quarter with inventory of two billion up 6% sequentially in anticipation of revenue growth in future quarters. Our days of inventory on hand were 69 days in Q2 as we continue to remain disciplined on how we manage inventory across the ecosystem. We ended the second quarter with 9.5 billion of cash and 69.4 billion of gross principal debt. Subsequent to quarter end, we repaid 1.6 billion of debt, resulting in gross principal debt of 67.8 billion. The weighted average coupon rate and years to maturity of our 59.8 billion in fixed rate debt is 3.8% and seven years respectively. The weighted average interest rate and years to maturity of our 8 billion in floating rate debt is 5.3% and 2.6 six years respectively. Turning to capital allocation, in Q2 we paid stockholders 2.8 billion of cash dividends based on a quarterly common stock cash dividend of 59 cents per share. In Q2, we repurchased 4.2 billion or approximately 25 million shares of common stock. In Q3, we expect the non-GAAP diluted share count to be approximately 4.97 billion shares, excluding the potential impact of any share repurchases. Now, moving on to guidance. Our guidance for Q3 is for consolidated revenue of 15.8 billion, of 21% year-on-year. We forecast semiconductor revenue of approximately 9.1 billion up 25% yearonear. Within this we expect Q3 AI semiconductor revenue of 5.1 billion up 60% yearonear. We expect infrastructure software revenue of approximately 6.7 billion up 16% yearonear. For modeling purposes, we expect Q3 consolidated gross margin to be down approximately 130 basis points sequentially, primarily reflecting a higher mix of XPUs within AI revenue. As a reminder, consolidated gross margins through the year will be impacted by the revenue mix of infrastructure, software, and semiconductors. We expect Q3 adjusted EBIDA to be at least 66%. We expect the non-GAAP tax rate for Q3 in fiscal year 2025 to remain at 14%. And with this, that concludes my prepared remarks. Operator, please open up the call for questions. Thank you. To ask a question, you will need to press star one on your telephone. To withdraw your question, please press star one again. Due to time restraints, we ask that you please limit yourself to one question. Please stand by while we compile the Q&A roster. And our first question will come from the line of Ross Seymour with Deutsche Bank. Your line is open. Hi guys, thanks for let me ask a question. Hawk, I wanted to jump onto the AI side and specifically some of the commentary you had about next year. Can you just give a little bit more color on the inference commentary you gave and and is it more the uh XPU side, the connectivity side or both that's given you the confidence to talk about the growth rate that you have this year being matched next fiscal year? Uh thank you Ross. Good question. I think we're indicating that what we are seeing and what we have quite a bit of visibility increasingly is increased deployment of XPUs. next year and much more than we originally thought and hand in hand with it of course more uh more and more networking. So it's a combination of both in the imprint side of things. Uh yeah we're seeing much more inference now. Thank you. Thank you. One moment for our next question. And that will come from the line of Harlon sir with JP Morgan. Your line is open. Good afternoon. Thanks for taking my question and uh great job on the quarterly execution. Hawk, you know, good to see the positive growth inflection quarter quarter year-over-year growth rates in your AI business. You as the team has mentioned right the quarters can be a bit lumpy. So if I smooth out kind of first three quarters of this fiscal year, your AI business is up 60% year-over-year. It's kind of right in line with your three-year kind of SAM growth ker right given your prepared remarks and you know knowing that your lead times remain at 35 weeks or better. Do you see the Broadcom team sustaining the 60% year-over-year growth rate exiting this year? And I assume that that potentially implies that you see your AI business sustaining the 60% year-over-year growth rate into fiscal 26 again based on your prepared commentary which again is in line with your SAM growth maker. Is that kind of the a fair way to think about the trajectory this year and next year? you Holland that's a very insightful set of uh analysis here and that's exa exactly what we're trying to do here because six over six months ago we gave you guys a point a year 2027 as we come into the second now into the second half of 2025 and with improved visibility and updates we're seeing in the way our hypers scale partners are deploying data centers AI classes. We are providing you more some level of uh thought guidance visibility what we are seeing how the trajectory of 26 might look like. I'm not giving you any update on 27. We're just still establishing the update we have in 27 6 months ago. But what we're doing now is giving you more visibility into where we're seeing 26 headed. But is the framework that you laid out for us like second half of last year which implies 60% kind of growth ker and your SAM opportunity is that kind of the right way to think about it as it relates to the profile of growth in your business this year and next year? Yes. Okay. Thank you, Hawk. Thank you. One moment for our next question. And that will come from the line of Ben Rezes with Melius Research. Your line is open. Hey, how you doing? Thanks, guys. Hey, Hawk. Um, networking, AI networking was really strong in the quarter. Um, and it it it seemed like it must have beat expectations. I was wondering if you could just talk about the networking in particular, what what caused that and how much of that is your acceleration into next year and uh when do you think you see Tomahawk kicking in as part of that acceleration? Thanks. Well, I I think the uh network AI networking as you probably would know uh goes pretty hand inhand with deployment of AI accelerator clusters. It isn't it doesn't deploy uh on a timetable that's very different from the way the accelerators get deployed whether they are XPUs or GPUs. It does happen and yet deployed a lot in scale out where Ethernet of course is the choice of protocol but it's also increasingly moving into the space of what we all call scale up within those data centers where you have much higher more than we originally thought consumption or density of switches than you have in the scale out scenario. It's in fact the increased density in scale out is 5 to 10 times more than in scale out. And that's the part that kind of pleasantly surprises and which is why this past quarter Q2 uh the AI networking portion continues at about 40% from when we reported a quarter ago for Q1. And uh at that time I said I expect it to drop. It hasn't. And and your thoughts on Tomahawk driving acceleration for next year and and when it kicks in? Oh, Tomahawk 6. Oh yeah, there's extremely strong interest. Uh now we're not shipping uh big orders or any orders other than basic proof of concepts out to customers. But there is tremendous demand for this new 102 terabit per second uh tomahawk switches. Thanks H. Thank you. One moment for our next question. And now we'll come from the line of Blaine Curtis with Jeff. Your line is open. Hey, thanks and great results. I just want to ask maybe following up on the scale out opportunity. So today I guess your main customer is not really using kind of an MVLink switch style scaleup. I'm just kind of curious your visibility or the timing in terms of when you might be shipping you know a switched Ethernet scale up network to your customers. Talking scale up scale scale up. Yeah. Well sca scale up is very rapidly converting to Ethernet now. Very much so. It's I for our fairly narrow band of hypers scale customers scale up is very much isn't it? Thank you. One moment for our next question and that will come from the line of Stacy Rascon with Bernstein. Your line is open. Hi guys, thanks for taking my questions. Um, Hawk, I still wanted to follow up on on that AI 2026 question. I want to just put some numbers on it just just to make sure I've got it right. So, if you you did 60% in the first three quarters of this year, if you grow 60% year-over-year in Q4, it would put you at like I don't know 5.8 billion, something like 19 or 20 billion for the year. And then are you act are you saying you're going to grow 60% in 2026 which would would put you 30 billion plus in AI revenues for 2026. I just want to make is that the math that you're you're trying to communicate to us directly. I think you're doing the math. I'm giving you the trend but I did answer that question. I think Harland asked earlier the the rate we are seeing and now so far in fiscal 25 and will presumably continue we don't see any reason why it doesn't given lead time visibility in 25 uh what we're seeing today based on what we have visibility uh on 26 is to be able to ram up this AI revenue in the same trajectory. Yes. So is the SAM going up? So is the SAM going up as well because now you have inference on top of trading. So is the SAM SAM still 60 to 90 or is the SAM higher now? How as as you see it? I don't I'm not playing a same game here. I'm just giving a trajectory towards where we drew the line on 27 before. So I have no no response to is the same going up or not. Stop talking about Sam. No. Thanks. Oh, okay. Thank you. One moment for our next question and that will come from the line of Vivic Arya with Bank of America. Your line is open. Uh, thanks for taking my question. I had a near and then a longerterm question on the XDU uh business. So hawk for near-term if your networking upsided in in Q2 and overall AI in was in line it means XCU was perhaps not as strong. So I I realize it's it's lumpy but anything more to read into that any product transition or or anything else. So just just a clarification there. And then longer term you know you have outlined um number of additional customers that you're working with. What milestones should we look forward to and what milestones are you watching uh to give you the confidence that you can now start adding uh that addressable opportunity into your 27 or or 28 or or other uh numbers like how do we get the confidence that these projects are going to turn into revenue in some you know reasonable uh time frame from now? Thank you. Okay, on the first part that you're asking, it's you know it's like you're trying to be you're trying to count how many angels on the head of a pin here. I mean whether it's XPU or uh or networking networking is hot but that doesn't mean XPU is any soft softer. It's very much along the trajectory we expect it to be and there's no lumpiness, there's no softening. It's pretty much what we expect the trajectory to go so far and into next quarter as well and probably beyond. So we have a fair it's a fairly uh uh I guess in our view a fairly clear visibility on the short-term trajectory in terms of going on to 27. No, we are not updating any numbers here. We six months ago we drew a sense for the size of the SAM based on you know uh million XP a million GPU XPU clusters for three customers and that's still very valid at that point that you'll be there but and we have not provided any further updates here nor are we intending to at this point when we get a better visibility clearer sense of where we are and that probably won't happen until 26. Uh we'll be happy to give an update to the audience. But right now though to in today's prepared remarks and answering a couple of questions we have we are as we are doing as we have done here we are intending to give you guys more visibility what we seeing the growth trajectory in 26 Thank you. One moment for our next question. And that will come from the line of CJ Muse with Caner Fitzgerald. Your line is open. Yeah, good afternoon. Thank you for taking the question. I was hoping to follow up on Ross' question regarding inference opportunity. Can you discuss workloads that are optimal that you're seeing for for custom silicon and that over time what percentage of your XPU business could be inference versus training? Thank you. I think there's no differentiation between training and inference in using uh merchant accelerators versus custom accelerators. I think the under the the whole premise behind going towards custom accelerators uh continues which is it's not a matter of cost alone. It is that as custom accelerators get used and get developed on a on a road map with any particular hyperscaler. Uh there's a learning cur curve a learning curve on how they could optimize the way the al the algorithms on their large language models gets written and tied to silicon. And that ability to do so is a huge value added in creating uh algorithms that can drive their LLMs to higher and higher performance much more than uh basically a a se a segregation approach between hardware and the software. is that you've literally combined end to end hardware and software as they take that as they take that journey and it's a journey. They don't learn that in one year. Do it a few cycles, get better and better at it. And there lies the value, the fundamental value in creating your own hardware versus using a third party merchant silicon that you are able to optimize uh your software to the hardware and event and eventually achieve way high performance than you otherwise could. and we see that happening. Thank you. One moment for our next question and that will come from the line of Carl Arian with BNP Parabus. Your line is open. Yes, thank you. Um Hawk, you spoke about the uh the much higher content opportunity in scale up networking. I was hoping you could discuss how important is demand adoption for uh c uh co- package optics in uh in in achieving this 5 to 10x higher content for scaleup networks uh or should we anticipate much of the scale up opportunity will be driven by uh tomahawk and thor nicks thank you uh I mean I'm trying to decipher this question of yours so let me try to answer it perhaps in a way I thing you want me to clarify first and foremost I think most of what's scaling up the a lot of the scaling up that's going as I call it which means a lot of uh XPU or GPU to GPU interconnects is done on copper copper interconnects and because you know the the size of the size of this in uh of this uh scale up cluster still not that huge yet that you can get away with copper to uh using copper interconnects and they're still doing it mostly they're doing it today at some point soon I believe when you start trying to go beyond maybe 72 GPU to GPU interconnects you may have to push towards a different uh protocol uh by protocol more than that different media from copper to optical and when we do that yeah perhaps then things like uh exotic stuff like coal packaging might be for of uh silicon with optical might become relevant but truly what we really are talking about is that at some stage as the clusters get larger And which means scale up becomes much bigger and you need to interconnect GPU or XPU to each other in scale up many more than just 72 or 100 maybe even 128 you start going more and more you want to use optical interconnects simply because of distance and that's when optical will start replacing copper and when that happens. The question is what's the best way to uh deliver on optical and one way is co- package optics but it's not the only way you can just simply use continue use perhaps pluggable at low cost optics in which case then you can interconnect the bandwidth uh the radics of a switch and our switch is now 512 connection S so you can now connect all these uh XPUs GPUs 512 for scale up phenomenon and that was huge but that that's when you go to optical that's going to happen I think within my view a year or two and we'll be right in the forefront of it and it may be co- package optics which we are very much in development but it's a lock in co- package or it could just be as a first have pluggable optics. Whatever it is, I think the bigger question is when does it go from optical and from copper connecting GPU to GPU to optical connecting it and the the stamp in that move will be huge and it's not necessary package optics. So that's definitely one path we are pursuing. Very clear. Thank you. And one moment for our next question and that will come from the line of Joshua Buck Halter with TD Cowan. Your line is open. Hey guys, thank you for taking my question. Um, I realize it's a bit nitpicky, but I wanted to ask about gross margins in the guide. Um, so your revenue implies sort of $800 million incremental increase with gross profit up I think 400 to 450 million which is kind of pretty well below corporate average fall through. um appreciate that semiis is dilutive and and custom is probably dilutive within semiis but anything else going on with margins that we should be aware of and and how should we think about the margin profile of custom longer term as that business continues to scale and diversify. Thank you. Yeah, we've historically said that the XPU margins are slightly lower um than the rest of the business other than wireless and so there's really nothing else going on other than that. It's just just exactly what I said that the majority of it quarter over quarter it 130 basis point decline is being driven by more XPUs. You know there are more moving parts here then your simple analysis proves here and I think your simple analysis is totally wrong in that regard. All right. And thank you. And one moment for our next question and that will come from the line of Timothy Aruri with UBS. Your line is open. Thanks a lot. Uh, um, I also wanted to ask about scale up Hawk. So, um, there's a lot of competing ecosystems. There's UA Link, which of course you left, and now there's the big, you know, GPU company, um, you know, opening up NVLink, and they're both trying to build eco systems. And there's an argument that you're an ecosystem of one. Uh what would you say to that debate? Does does does opening up NVLink change the landscape and sort of how do you view of your AI networking growth next year? Do you think it's going to be primarily driven by scale up or would still be pretty scale outheavy? Thanks. It's you know people do like to create platforms and new protocols and system. The fact of the matter is scale up can just be done easily and it's currently available. It's open standards, opensource Ethernet just as well. Just as well, you don't need to create new systems for the sake of doing something that you could easily be doing in networking in Ethernet. And so, yeah, I hear a lot of this interesting new protocols, standards that are trying to be created. And most of them, by the way, are proprietary, much as they like to call it otherwise. What is really open source and open standards is internet and we believe internet will prevail as it does in before for the last 20 years in traditional networking. There no reason to create a new standard for something that could be easily done in transferring bits and byes of data. Got it. Thank you. And one moment for our next question and that will come from the line of Christopher Roland with Susuana. Your line is open. Thanks for the question. Um yeah, my my my question is for you Hawk. It's a kind of a bigger picture one here. And um this this kind of acceleration that we're seeing in AI demand. Uh do do you think that this acceleration is because of a marked improvement in uh AS6 or XP or XPUs closing the gap on the software side uh at your customers? Do you think it's um these require token uh tokconomics around inference uh test time compute driving that for example? What do you think is actually driving the upside here and do you think it leads to a market share shift uh faster than we were expecting towards XPU from GPU? Thanks. Yeah, interesting question but no none of the forgoing that you outlined. It's very simple. Why inference has come out uh very very hot lately is no remember we're only selling to a few customers hyperscalers with platforms and LLMs that's it there are not that many and and you we told you how many we have and we haven't increased any but what is happening is this all uh these hyperscalers and those with LN MS need to justify all this spending they're doing. Doing training makes your frontier models smarter. There's no question. It's almost like science research and science. Make your frontier models by creating very clever algorithms that that consumes a lot of compute for training smarter. Training makes it smarter. You want to monetize inference and that's what's driving it. monetize as I indicated in my prepared remarks the drive to justify a return on investment and a lot of that investment is training and that return on investment is by creating use cases a lot AI use cases AI consumption out there through availability of a lot of inference and that's what we are now starting to see among a small group of customers. Excellent. Thank you. And one moment for our next question and that will come from the line of Vayesh with Mazuo. Your line is open. Yeah, thanks. Hi Hawk. Uh just going back on the AI server revenue side. Um I know you said fiscal 25 kind of tracking to that up 60%age growth. As you look at crystal 26, you know, you have many new customers rapping a meta and probably, you know, you have the four of the six hyperscalers that you have talked in the past. Would you expect that growth to accelerate into fiscal 26 uh above that you know kind of the 60% they talked about you know my my my prepared remarks and which I clarify that the rate of growth we are seeing in 25 will sustain into 26 based on improved visibility and the fact that we're seeing inference coming in on top of the demand for training as the clusters get build up bigger and bigger still stands I don't think we are getting very far by trying to pass through my words or data here. It's just a it is and we see that going from 25 into 26 as the best uh forecast we have at this point. Got it. and and on the NVLink uh the NV link fusion versus the scaleup uh do you expect that market to go the route of top of the rack where you're seeing some move to the Ethernet side um in in in kind of the scale out do you expect scale up to kind of go the same route um thanks well Broadcom do not participate in NV link so uh I'm really not qualified to answer that question I think right thank you. Thank you. One moment for our next question. And that will come from the line of Aaron Rakers with Wells Fargo. Your line is open. Yeah, thanks uh for taking the question. And I think all my questions on scale up have been asked, but I I guess how given the execution that that you guys have have been able to do with the VMware integration looking at the balance sheet, looking at the debt structure, I'm curious if you know if you could give us your thoughts on how the company thinks about you know capital return versus you know the thoughts on you know M&A and the strategy going forward. Thank you. Okay, that's a that's an interesting question and and I agree not to uh not too untimely I would say because yeah we have done a lot of the integration of VMware now and you can see that in the in the level of free cash flow we're generating from operations and as we said the use of capital has always been uh we're very I guess uh measured and upfront with a return through dividends which is half our free cash flow of the preceding year and frankly as Kirsten has mentioned three months ago and six months ago to in the last two earnings call the first choice typically of the other free part of the free cash flow is to bring down our debt to a more to a level uh that we feel closer to no more than two uh ratio a ratio of ratio of debt to IIDA. Um, and that doesn't mean that opportunistically we may go out there and buy back our shares as we did last quarter and indicated by Kirstson when we did $4.2 billion of stock buyback. Now part of it is used to uh basically when RS employee RS use vest basically use we basically buy back part of the shares in uh for used to be paying taxes on the invested RSU. But the other part of it I do a I do admit we use it opportunistically last quarter when we see an opportunity uh situation when basically we think that it's a good time to buy some shares back. We do. But having said all that our use of cash outside of dividends would be at this stage used towards reducing our debt. And I know you're going to ask what about M&A? Well, the kind of M&A we will do would in our view would be significant would be substantial enough that we need debt in any case and it's a and it's a good use of a free cash flow to bring down debt to in a way expand if not preserve our borrowing capacity if we have to do another M&A deal. Thank you. One moment for our next question and that will come from the line of Shiny Pajuri with Raymond James. Your line is open. Thank you. H um couple of clarifications. First on your 2026 expectation, are you assuming any meaningful contribution from the uh four prospects that you talked about? No comment. We don't talk on prospects. We only talk on customers. Okay, fair enough. And then my other clarification is that I think you talked about um networking being about 40% of the mix within AI. Is that the right kind of mix that you expect going forward or is that you know going to materially change as we I guess you know see XPS ramping uh you know going forward? No, I've always said and I expect that to be the case in going forward in 26 as we grow that networking should be a ratio to XPU should be closer in the in the range of less than 30%. Not the 40%. Thank you. One moment for our next question and that will come from the line of Joe Moore with Morgan Stanley. Your line is open. Great. Thank you. Um, you've said you're not going to be impacted by export controls on AI. I I know there's been a number of changes since in the industry since the last time you made the call. Is that still the case? And just, you know, can you give people comfort that you there's no impact from that down the road? Nobody can give anybody comfort in this environment. Joe, you know that rules are changing quite dramatically as trade bilateral trade uh agreements are continue to be negotiated on a very very uh dynamic environment. So I'll be honest I don't I don't know I know as little as probably you probably know more than I do maybe in which case then I know very little about this whole thing about h whether there's any export control how the export control will take place but guessing so I rather not answer that because no I don't know whether it will be thank you and we do have time for one final question and that will come from the line of Williamstein with truest securities. Your line is open. Oh, great. Thank you for squeezing me in. Um, I wanted to ask about VMware. Uh, can you comment as to how far along you are in the process of uh converting customers uh to uh the subscription model? Is that uh close to complete or is there still a number of quarters that we should expect uh that that uh that conversion continues? That's a good question and so let me start off by saying a good way to measure it is you know most most of our VMware contracts are about three on uh typically 3 years and that was what VMware did before we acquired them and that's pretty much what we continue to do three years very traditional so based on that the renewals we're like twothirds of the way almost two halfway more than halfway through the renewals So, we probably have at least another year plus, maybe a year and a half to go. Thank you. And with that, I'd like to turn the call over to GU for closing remarks. Thank you. Operator Rodcom currently plans to report its earnings for the third quarter of fiscal year 2025 after close of market on Thursday, September 4th, 2025. A public webcast of Broadcom's earnings conference call will follow at 2 p.m. Pacific. That will conclude our earnings call today. Thank you all for joining. Operator, you may end the call."
}